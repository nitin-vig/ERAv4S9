2025-11-02 01:28:41,259 - INFO - ================================================================================
2025-11-02 01:28:41,259 - INFO - ImageNet Training on EC2 - Multi-GPU Setup
2025-11-02 01:28:41,260 - INFO - ================================================================================
2025-11-02 01:28:41,260 - INFO - Device: cuda:0
2025-11-02 01:28:41,260 - INFO - Distributed: False, Rank: 0, World Size: 1
2025-11-02 01:28:41,278 - INFO - CUDA Available: True, GPU Count: 1
2025-11-02 01:28:42,040 - INFO - ‚úÖ ImageNet dataset found at //lambda/nfs/ERAv4S09/ERAv4S9/data/imagenet1k
   Train classes: 1000
   Validation classes: 1000
   Expected: 1000 classes each
2025-11-02 01:28:42,040 - INFO - Dataset: Imagenet1K
2025-11-02 01:28:42,040 - INFO - Batch size: 512
2025-11-02 01:28:42,040 - INFO - Epochs: 100
2025-11-02 01:28:42,040 - INFO - Learning rate: 0.08
2025-11-02 01:28:42,040 - INFO - üìÇ Loading Imagenet1K dataset from: //lambda/nfs/ERAv4S09/ERAv4S9/data...
2025-11-02 01:29:18,974 - INFO - Training samples: 1159338
2025-11-02 01:29:18,974 - INFO - Validation samples: 50000
2025-11-02 01:29:18,974 - INFO - Batches per epoch: 2265
2025-11-02 01:29:18,975 - INFO - ü§ñ Creating ResNet50 model...
2025-11-02 01:29:19,666 - INFO - üì¶ Loading tiny_imagenet weights from: ./tiny_imagenet_stage_2/final_model.pth
2025-11-02 01:29:19,823 - INFO -    Current model (ImageNet): 1000 classes
2025-11-02 01:29:19,823 - INFO -    Pretrained model (Tiny ImageNet): 200 classes
2025-11-02 01:29:19,824 - INFO -    ‚ö†Ô∏è  Final layer size mismatch! Filtering out fc layer
2025-11-02 01:29:19,832 - INFO -    ‚ö†Ô∏è  Missing keys (expected for FC layer): 2
2025-11-02 01:29:19,832 - INFO - ‚úÖ Successfully loaded tiny_imagenet weights
2025-11-02 01:29:19,833 - INFO - üîç Running Learning Rate Finder...
2025-11-02 01:29:33,531 - ERROR - ‚ùå LR Finder failed: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 363.56 MiB is free. Including non-PyTorch memory, this process has 39.12 GiB memory in use. Of the allocated memory 38.57 GiB is allocated by PyTorch, and 62.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-11-02 01:29:33,537 - ERROR - Traceback (most recent call last):
  File "/lambda/nfs/ERAv4S09/ERAv4S9/train_imagenet_ec2.py", line 602, in main
    optimal_lr = find_optimal_lr(
                 ^^^^^^^^^^^^^^^^
  File "/lambda/nfs/ERAv4S09/ERAv4S9/lr_finder.py", line 55, in find_optimal_lr
    lr_finder.range_test(
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch_lr_finder/lr_finder.py", line 345, in range_test
    loss = self._train_batch(
           ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch_lr_finder/lr_finder.py", line 410, in _train_batch
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lambda/nfs/ERAv4S09/ERAv4S9/models.py", line 114, in forward
    x = self.layer3(x)
        ^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lambda/nfs/ERAv4S09/ERAv4S9/models.py", line 44, in forward
    out = self.bn3(out)
          ^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 363.56 MiB is free. Including non-PyTorch memory, this process has 39.12 GiB memory in use. Of the allocated memory 38.57 GiB is allocated by PyTorch, and 62.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-11-02 01:29:33,538 - INFO -    Continuing with default/configured LR...
2025-11-02 01:29:33,688 - INFO - üöÄ Starting training...
2025-11-02 01:29:33,688 - INFO -    Start epoch: 0, Total epochs: 100
