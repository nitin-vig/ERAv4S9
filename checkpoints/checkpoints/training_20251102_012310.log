2025-11-02 01:23:10,112 - INFO - ================================================================================
2025-11-02 01:23:10,112 - INFO - ImageNet Training on EC2 - Multi-GPU Setup
2025-11-02 01:23:10,112 - INFO - ================================================================================
2025-11-02 01:23:10,113 - INFO - Device: cuda:0
2025-11-02 01:23:10,113 - INFO - Distributed: False, Rank: 0, World Size: 1
2025-11-02 01:23:10,131 - INFO - CUDA Available: True, GPU Count: 1
2025-11-02 01:23:11,073 - INFO - ‚úÖ ImageNet dataset found at //lambda/nfs/ERAv4S09/ERAv4S9/data/imagenet1k
   Train classes: 1000
   Validation classes: 1000
   Expected: 1000 classes each
2025-11-02 01:23:11,074 - INFO - Dataset: Imagenet1K
2025-11-02 01:23:11,074 - INFO - Batch size: 896
2025-11-02 01:23:11,074 - INFO - Epochs: 100
2025-11-02 01:23:11,074 - INFO - Learning rate: 0.1
2025-11-02 01:23:11,074 - INFO - üìÇ Loading Imagenet1K dataset from: //lambda/nfs/ERAv4S09/ERAv4S9/data...
2025-11-02 01:23:52,929 - INFO - üìä Computing dataset mean/std statistics...
2025-11-02 01:24:04,917 - INFO - 
üí° Suggested normalization values:
2025-11-02 01:24:04,917 - INFO -    mean = [0.48219549655914307, 0.45888248085975647, 0.40965166687965393]
2025-11-02 01:24:04,918 - INFO -    std = [0.22905518114566803, 0.22517578303813934, 0.22560001909732819]
2025-11-02 01:24:04,918 - INFO - 
   Update config.py AUGMENTATION section with these values
2025-11-02 01:24:04,926 - INFO -    Saved to: ./checkpoints/dataset_stats.json
2025-11-02 01:24:04,926 - INFO - Training samples: 1159338
2025-11-02 01:24:04,927 - INFO - Validation samples: 50000
2025-11-02 01:24:04,927 - INFO - Batches per epoch: 1294
2025-11-02 01:24:04,927 - INFO - ü§ñ Creating ResNet50 model...
2025-11-02 01:24:05,241 - INFO - üì¶ Loading tiny_imagenet weights from: ./tiny_imagenet_stage_2/final_model.pth
2025-11-02 01:24:05,400 - INFO -    Current model (ImageNet): 1000 classes
2025-11-02 01:24:05,400 - INFO -    Pretrained model (Tiny ImageNet): 200 classes
2025-11-02 01:24:05,400 - INFO -    ‚ö†Ô∏è  Final layer size mismatch! Filtering out fc layer
2025-11-02 01:24:05,408 - INFO -    ‚ö†Ô∏è  Missing keys (expected for FC layer): 2
2025-11-02 01:24:05,408 - INFO - ‚úÖ Successfully loaded tiny_imagenet weights
2025-11-02 01:24:05,409 - INFO - üîç Running Learning Rate Finder...
2025-11-02 01:24:29,154 - ERROR - ‚ùå LR Finder failed: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacity of 39.49 GiB of which 759.56 MiB is free. Including non-PyTorch memory, this process has 38.72 GiB memory in use. Of the allocated memory 38.21 GiB is allocated by PyTorch, and 24.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-11-02 01:24:29,162 - ERROR - Traceback (most recent call last):
  File "/lambda/nfs/ERAv4S09/ERAv4S9/train_imagenet_ec2.py", line 602, in main
    optimal_lr = find_optimal_lr(
                 ^^^^^^^^^^^^^^^^
  File "/lambda/nfs/ERAv4S09/ERAv4S9/lr_finder.py", line 55, in find_optimal_lr
    lr_finder.range_test(
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch_lr_finder/lr_finder.py", line 345, in range_test
    loss = self._train_batch(
           ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch_lr_finder/lr_finder.py", line 410, in _train_batch
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lambda/nfs/ERAv4S09/ERAv4S9/models.py", line 113, in forward
    x = self.layer2(x)
        ^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lambda/nfs/ERAv4S09/ERAv4S9/models.py", line 43, in forward
    out = self.conv3(out)
          ^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.local/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacity of 39.49 GiB of which 759.56 MiB is free. Including non-PyTorch memory, this process has 38.72 GiB memory in use. Of the allocated memory 38.21 GiB is allocated by PyTorch, and 24.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2025-11-02 01:24:29,162 - INFO -    Continuing with default/configured LR...
2025-11-02 01:24:29,712 - INFO - üöÄ Starting training...
2025-11-02 01:24:29,712 - INFO -    Start epoch: 0, Total epochs: 100
