{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WacZdFIK8Wxm"
      },
      "source": [
        "# Multi-Dataset ImageNet Training with ResNet50 - Modular Version\n",
        "\n",
        "This notebook demonstrates training ResNet50 on multiple ImageNet variants using a modular approach. The code supports experiments across different datasets for comprehensive analysis.\n",
        "\n",
        "## Supported Datasets:\n",
        "- **ImageNette**: 10 classes, 224x224 images (fastest for experiments)\n",
        "- **Tiny ImageNet**: 200 classes, 64x64 images (medium complexity)\n",
        "- **ImageNet Mini**: 1000 classes, 224x224 images (subset of full ImageNet)\n",
        "- **Full ImageNet**: 1000 classes, 224x224 images (full dataset)\n",
        "\n",
        "## Features:\n",
        "- **Modular Design**: Separate modules for configuration, data loading, models, and training utilities\n",
        "- **Multi-Dataset Support**: Easy switching between different ImageNet variants\n",
        "- **Dataset-Specific Training**: Optimized hyperparameters for each dataset\n",
        "- **Comprehensive Metrics**: Tracks training and validation metrics\n",
        "- **Model Saving**: Automatic model checkpointing with dataset-specific naming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "iHlSAbeh8JPX",
        "outputId": "14389be0-2ae3-48e0-c202-f39f76d2beb1"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid character 'Ô∏è' (U+FE0F) (ipython-input-3507605965.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3507605965.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1Ô∏è‚É£ Mount Google Drive\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character 'Ô∏è' (U+FE0F)\n"
          ]
        }
      ],
      "source": [
        "# 1Ô∏è‚É£ Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# 2Ô∏è‚É£ Define your Drive path (folder + file)\n",
        "drive_folder = '/content/gdrive/My Drive/models'\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "file_path = os.path.join(drive_folder, 'dummy_direct_save.txt')\n",
        "\n",
        "# 3Ô∏è‚É£ Write directly to Google Drive\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(\"‚úÖ This file was written directly to Google Drive.\\n\")\n",
        "\n",
        "print(f\"üìÇ File written directly to: {file_path}\")\n",
        "\n",
        "# 4Ô∏è‚É£ Verify it exists\n",
        "!ls -lh \"/content/gdrive/My Drive/models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QG8Wassd8Wxp"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install torchsummary albumentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9sgaqmb9ghJ",
        "outputId": "4c2508cf-d806-4a0a-ba38-1d2a2f27ef10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rmdir: failed to remove 'ERAv4S9': No such file or directory\n",
            "Cloning into 'ERAv4S9'...\n",
            "remote: Enumerating objects: 160, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 160 (delta 84), reused 97 (delta 34), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (160/160), 3.66 MiB | 7.40 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n",
            "/content/ERAv4S9\n",
            "total 2360\n",
            "-rw-r--r-- 1 root root   13109 Oct 28 00:19 config.py\n",
            "-rw-r--r-- 1 root root   25618 Oct 28 00:19 dataset_loader.py\n",
            "-rw-r--r-- 1 root root 2312132 Oct 28 00:19 ImageNet_Experiment_Resnet_50.ipynb\n",
            "-rw-r--r-- 1 root root    7655 Oct 28 00:19 models.py\n",
            "-rw-r--r-- 1 root root    4365 Oct 28 00:19 NOTEBOOK_MULTI_STAGE_GUIDE.md\n",
            "-rw-r--r-- 1 root root    3521 Oct 28 00:19 progressive_transfer_learning_example.py\n",
            "-rw-r--r-- 1 root root   10776 Oct 28 00:19 README.md\n",
            "-rw-r--r-- 1 root root     648 Oct 28 00:19 requirements.txt\n",
            "-rw-r--r-- 1 root root   20006 Oct 28 00:19 training_utils.py\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Clone the repo\n",
        "!rmdir ERAv4S9\n",
        "!git clone https://github.com/nitin-vig/ERAv4S9.git\n",
        "\n",
        "# Step 2: Move into the repo folder\n",
        "%cd ERAv4S9\n",
        "\n",
        "# Step 3: (Optional) List files to verify\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GCfedRJU8Wxq",
        "outputId": "fd25335c-4824-4d55-b3b1-7f54c21aeaaa"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-950443379.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgiou_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneralized_box_iou_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSqueezeExcitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compile_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackTrigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2339\u001b[0m }\n\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mhas_triton_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2342\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtriton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_triton.py\u001b[0m in \u001b[0;36mhas_triton_package\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhas_triton_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtriton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtriton_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtriton_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# submodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from .runtime import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mautotune\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/runtime/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautotuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAutotuner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeuristics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautotune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRedisRemoteCacheBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRemoteCacheBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJITFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKernelInterface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMockTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinterpret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOutOfResources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInterpreterError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/runtime/autotuner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mknobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKernelInterface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOutOfResources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPTXASError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Import all necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Import our modular components\n",
        "from config import Config\n",
        "from dataset_loader import get_data_loaders, visualize_samples\n",
        "from models import get_model, count_parameters, get_model_summary, save_model\n",
        "from training_utils import train_model, train_model_with_transfer, evaluate_model, MetricsTracker, verify_saved_files\n",
        "\n",
        "print(Config.__dict__)\n",
        "\n",
        "print(\"All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LKzKXeB8Wxr"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "Let's configure our training parameters. You can easily switch between datasets and modify training parameters here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sbHsrds8Wxr"
      },
      "outputs": [],
      "source": [
        "# Configuration setup for multi-dataset experiments\n",
        "# You can easily switch between datasets by changing DATASET_NAME\n",
        "\n",
        "# Dataset configuration\n",
        "DATASET_NAME = \"imagenette\"  # Options: \"imagenette\", \"tiny_imagenet\", \"imagenet_mini\", \"imagenet\"\n",
        "USE_PRETRAINED = False  # Custom implementation without pretrained weights\n",
        "\n",
        "# Update configuration for the selected dataset\n",
        "Config.update_for_dataset(DATASET_NAME)\n",
        "\n",
        "print(\"Configuration updated!\")\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"Image size: {Config.IMAGE_SIZE}\")\n",
        "print(f\"Number of classes: {Config.NUM_CLASSES}\")\n",
        "print(f\"Batch size: {Config.BATCH_SIZE}\")\n",
        "print(f\"Epochs: {Config.NUM_EPOCHS}\")\n",
        "print(f\"Learning rate: {Config.LEARNING_RATE}\")\n",
        "print(f\"Use pretrained: {USE_PRETRAINED}\")\n",
        "\n",
        "# Display dataset-specific training parameters\n",
        "dataset_config = Config.get_dataset_config(DATASET_NAME)\n",
        "print(f\"\\nDataset-specific parameters:\")\n",
        "print(f\"Optimizer: {dataset_config['optimizer']}\")\n",
        "print(f\"Scheduler: {dataset_config['scheduler']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTitVrnx8Wxr"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "Setup the environment and check GPU availability. For full ImageNet training, you'll need significant computational resources.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hms3ZX-O8Wxs"
      },
      "outputs": [],
      "source": [
        "# Setup environment\n",
        "def setup_environment():\n",
        "    \"\"\"Setup environment for ImageNet training\"\"\"\n",
        "    print(\"Setting up environment for ImageNet training...\")\n",
        "\n",
        "    # Create necessary directories\n",
        "    os.makedirs(Config.DATA_ROOT, exist_ok=True)\n",
        "    os.makedirs(Config.SAVE_MODEL_PATH, exist_ok=True)\n",
        "\n",
        "    print(\"Environment setup complete!\")\n",
        "\n",
        "def check_gpu_availability():\n",
        "    \"\"\"Check GPU availability and setup device\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        print(\"Warning: Full ImageNet training requires significant GPU memory!\")\n",
        "    else:\n",
        "        print(\"Warning: CPU training will be very slow for ImageNet!\")\n",
        "\n",
        "    return device\n",
        "\n",
        "# Run setup\n",
        "setup_environment()\n",
        "device = check_gpu_availability()\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW24PNlCUVQF"
      },
      "outputs": [],
      "source": [
        "# üß© Colab Dataset Setup Cell\n",
        "# Copy-paste this cell into your Colab notebook\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Install required packages (if not already installed)\n",
        "!pip install -q torch torchvision albumentations tqdm requests\n",
        "\n",
        "DATA_DIR = \"/content/data\"\n",
        "IMAGENETTE_DIR = os.path.join(DATA_DIR, \"imagenette2\")\n",
        "TINY_IMAGENET_DIR = os.path.join(DATA_DIR, \"tiny-imagenet-200\")\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def run_cmd(cmd):\n",
        "    \"\"\"Helper to run shell commands cleanly.\"\"\"\n",
        "    result = subprocess.run(cmd, shell=True, check=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(f\"‚ö†Ô∏è Warning: {cmd} failed with error:\\n{result.stderr}\")\n",
        "    return result\n",
        "\n",
        "# ------------------------------\n",
        "# üîπ Download ImageNette\n",
        "# ------------------------------\n",
        "if not os.path.exists(IMAGENETTE_DIR) or len(os.listdir(IMAGENETTE_DIR)) == 0:\n",
        "    print(\"üîÑ Downloading ImageNette...\")\n",
        "    run_cmd(\"wget -q https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\")\n",
        "    run_cmd(\"tar -xzf imagenette2.tgz\")\n",
        "    run_cmd(f\"mv imagenette2 {DATA_DIR}/\")\n",
        "    run_cmd(\"rm imagenette2.tgz\")\n",
        "    print(\"‚úÖ ImageNette downloaded!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Skipping ImageNette ‚Äî already exists at {IMAGENETTE_DIR}\")\n",
        "\n",
        "# ------------------------------\n",
        "# üîπ Download Tiny ImageNet\n",
        "# ------------------------------\n",
        "if not os.path.exists(TINY_IMAGENET_DIR) or len(os.listdir(TINY_IMAGENET_DIR)) == 0:\n",
        "    print(\"üîÑ Downloading Tiny ImageNet...\")\n",
        "    run_cmd(\"wget -q http://cs231n.stanford.edu/tiny-imagenet-200.zip\")\n",
        "    run_cmd(\"unzip -q tiny-imagenet-200.zip\")\n",
        "    run_cmd(f\"mv tiny-imagenet-200 {DATA_DIR}/\")\n",
        "    run_cmd(\"rm tiny-imagenet-200.zip\")\n",
        "    print(\"‚úÖ Tiny ImageNet downloaded!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Skipping Tiny ImageNet ‚Äî already exists at {TINY_IMAGENET_DIR}\")\n",
        "\n",
        "# ------------------------------\n",
        "# üîπ Verify\n",
        "# ------------------------------\n",
        "print(\"\\nüìÅ Dataset verification:\")\n",
        "!ls -la {DATA_DIR}\n",
        "!du -sh {DATA_DIR}/* | sort -h\n",
        "\n",
        "print(\"\\nüéâ Datasets ready! You can now use:\")\n",
        "print(\"from dataloader import get_data_loaders\")\n",
        "print(\"train_loader, test_loader = get_data_loaders('imagenette')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F9rBWIp8Wxs"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "Load the dataset and visualize some sample images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HCNpJBv8Wxs"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "train_loader, test_loader = get_data_loaders(DATASET_NAME)\n",
        "\n",
        "# Visualize some samples\n",
        "print(\"\\nVisualizing sample images...\")\n",
        "visualize_samples(train_loader, num_samples=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KrXECgD8Wxt"
      },
      "source": [
        "## Model Creation\n",
        "\n",
        "Create the ResNet50 model and display its architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ3Qqiq58Wxt"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "print(f\"Creating {Config.MODEL_NAME} model...\")\n",
        "model = get_model(\n",
        "    model_name=Config.MODEL_NAME,\n",
        "    dataset_name=DATASET_NAME,\n",
        "    pretrained=USE_PRETRAINED\n",
        ")\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Print model info\n",
        "print(f\"Model parameters: {count_parameters(model):,}\")\n",
        "\n",
        "# Get model summary\n",
        "dataset_config = Config.get_dataset_config(DATASET_NAME)\n",
        "input_size = (3, dataset_config[\"image_size\"], dataset_config[\"image_size\"])\n",
        "print(f\"\\nModel summary (input size: {input_size}):\")\n",
        "get_model_summary(model, input_size=input_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEBryc3p8Wxt"
      },
      "source": [
        "## Training\n",
        "\n",
        "Train the model using our modular training utilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1XNO6oM8Wxt"
      },
      "outputs": [],
      "source": [
        "# # Train model\n",
        "# stage_config = Config.STAGES[DATASET_NAME]\n",
        "# print(stage_config)\n",
        "# NUM_EPOCHS = stage_config[\"epochs\"]\n",
        "# BATCH_SIZE = stage_config[\"batch_size\"]\n",
        "# LEARNING_RATE = stage_config[\"lr\"]\n",
        "# WEIGHT_DECAY = stage_config[\"weight_decay\"]\n",
        "\n",
        "# print(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
        "# print(f\"Batch size: {BATCH_SIZE}\")\n",
        "# print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "# print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
        "\n",
        "# metrics_tracker = train_model(model, train_loader, test_loader, device, Config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM55R49L8Wxu"
      },
      "source": [
        "## Results Visualization\n",
        "\n",
        "Plot the training metrics and evaluate the final model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T6kFw9s8Wxu"
      },
      "outputs": [],
      "source": [
        "# # Plot training metrics\n",
        "# print(\"Plotting training metrics...\")\n",
        "# metrics_tracker.plot_metrics(save_path=f\"{Config.SAVE_MODEL_PATH}/training_metrics.png\")\n",
        "\n",
        "# # Final evaluation\n",
        "# print(\"\\nFinal evaluation...\")\n",
        "# test_loss, test_acc, test_top5_acc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "# print(f\"\\nTraining completed!\")\n",
        "# print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
        "# print(f\"Final Top-5 Accuracy: {test_top5_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-rY31PS8Wxu"
      },
      "source": [
        "## Model Saving\n",
        "\n",
        "Save the trained model to local storage and Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6ch59xH8Wxu"
      },
      "outputs": [],
      "source": [
        "# # Save final model\n",
        "# final_model_path = f\"{Config.SAVE_MODEL_PATH}/final_model.pth\"\n",
        "# save_model(model, final_model_path, epoch=NUM_EPOCHS, loss=test_loss)\n",
        "\n",
        "# # Save to Google Drive if mounted\n",
        "# if Config.MOUNT_DRIVE:\n",
        "#     drive_model_path = f\"{Config.DRIVE_MODEL_PATH}/final_model.pth\"\n",
        "#     save_model(model, drive_model_path, epoch=NUM_EPOCHS, loss=test_loss)\n",
        "#     print(f\"Model also saved to Google Drive: {drive_model_path}\")\n",
        "\n",
        "# print(\"Model saving completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSUjHImSSRw8"
      },
      "source": [
        "## Progressive Transfer Learning (Multi-Stage Training)\n",
        "\n",
        "Run multiple stages in sequence with automatic weight transfer from each stage to the next.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNYVAVF9SRw8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "PROGRESSIVE TRANSFER LEARNING - RUN SELECTED STAGES\n",
        "===================================================\n",
        "Train multiple stages in sequence with automatic weight transfer.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ‚öôÔ∏è CONFIGURATION - Choose which stages to run\n",
        "# ================================================\n",
        "STAGES_TO_RUN = [\"imagenette\", \"tiny_imagenet\"]  # Modify this list\n",
        "# Options: \"imagenette\", \"tiny_imagenet\", \"imagenet_mini\", \"imagenet\"\n",
        "# Order matters! Stages run in sequence with weight transfer\n",
        "\n",
        "USE_PRETRAINED_FOR_FIRST_STAGE = False  # Start with ImageNet pretrained weights?\n",
        "SAVE_RESULTS_AT_EACH_STAGE = True  # Save models and metrics at each stage?\n",
        "\n",
        "# Results storage\n",
        "all_stage_results = {}\n",
        "pretrained_weights_path = None\n",
        "\n",
        "# Verify save path exists (create if needed)\n",
        "print(\"üöÄ Progressive Transfer Learning Training\")\n",
        "print(f\"Stages to run: {STAGES_TO_RUN}\")\n",
        "print(f\"Start with pretrained: {USE_PRETRAINED_FOR_FIRST_STAGE}\")\n",
        "print(f\"Save at each stage: {SAVE_RESULTS_AT_EACH_STAGE}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check if save path exists\n",
        "save_path = Config.SAVE_MODEL_PATH\n",
        "if not os.path.exists(save_path):\n",
        "    print(f\"\\n‚ö†Ô∏è Save path doesn't exist: {save_path}\")\n",
        "    print(f\"Creating directory...\")\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    print(f\"‚úÖ Created: {save_path}\")\n",
        "else:\n",
        "    print(f\"\\nüìÅ Models will be saved to: {save_path}\")\n",
        "    print(f\"   (Directory exists)\")\n",
        "\n",
        "# Verify Google Drive is mounted (if using /gdrive)\n",
        "if save_path.startswith('/content/gdrive'):\n",
        "    gdrive_root = '/content/gdrive'\n",
        "    if not os.path.exists(gdrive_root):\n",
        "        print(f\"\\n‚ùå ERROR: Google Drive not mounted!\")\n",
        "        print(f\"Please run the 'Mount Google Drive' cell (Cell 11) first.\")\n",
        "        print(f\"After mounting, Google Drive will be available at: /content/gdrive\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Google Drive is mounted at: {gdrive_root}\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, stage_name in enumerate(STAGES_TO_RUN, 1):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"STAGE {i}/{len(STAGES_TO_RUN)}: {stage_name.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Update configuration for this stage\n",
        "    Config.update_for_dataset(stage_name)\n",
        "\n",
        "    # Get stage configuration\n",
        "    stage_config = Config.STAGES[stage_name]\n",
        "    print(f\"Classes: {stage_config['classes']}\")\n",
        "    print(f\"Image size: {stage_config['image_size']}\")\n",
        "    print(f\"Epochs: {stage_config['epochs']}\")\n",
        "    print(f\"Batch size: {stage_config['batch_size']}\")\n",
        "    print(f\"LR: {stage_config['lr']}\")\n",
        "    print(f\"Previous weights: {pretrained_weights_path or 'None (fresh start)'}\")\n",
        "\n",
        "    # Load dataset\n",
        "    print(f\"\\nüì¶ Loading {stage_name} dataset...\")\n",
        "    train_loader, test_loader = get_data_loaders(stage_name)\n",
        "\n",
        "    # Create model\n",
        "    print(f\"\\nüß† Creating model for {stage_name}...\")\n",
        "    use_pretrained = USE_PRETRAINED_FOR_FIRST_STAGE if (i == 1 and not pretrained_weights_path) else False\n",
        "    model = get_model(\n",
        "        model_name=Config.MODEL_NAME,\n",
        "        dataset_name=stage_name,\n",
        "        pretrained=use_pretrained\n",
        "    )\n",
        "    model = model.to(device)\n",
        "    print(f\"Model created: {count_parameters(model):,} parameters\")\n",
        "\n",
        "    # Determine next stage name for weight saving\n",
        "    next_stage = STAGES_TO_RUN[i] if i < len(STAGES_TO_RUN) else None\n",
        "\n",
        "    # Train with transfer learning\n",
        "    print(f\"\\nüèãÔ∏è Training {stage_name}...\")\n",
        "    metrics_tracker, final_weights = train_model_with_transfer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        test_loader=test_loader,\n",
        "        device=device,\n",
        "        config=Config,\n",
        "        pretrained_weights_path=pretrained_weights_path,\n",
        "        next_stage_name=next_stage\n",
        "    )\n",
        "\n",
        "    # Save results if requested\n",
        "    if SAVE_RESULTS_AT_EACH_STAGE:\n",
        "        stage_save_dir = f\"{Config.SAVE_MODEL_PATH}/{stage_name}_stage_{i}\"\n",
        "        os.makedirs(stage_save_dir, exist_ok=True)\n",
        "\n",
        "        # Save final model\n",
        "        final_model_path = f\"{stage_save_dir}/final_model.pth\"\n",
        "        torch.save(model.state_dict(), final_model_path)\n",
        "        print(f\"‚úÖ Saved model: {final_model_path}\")\n",
        "\n",
        "        # Save metrics\n",
        "        metrics_data = {\n",
        "            \"stage\": stage_name,\n",
        "            \"stage_number\": i,\n",
        "            \"final_train_loss\": metrics_tracker.train_losses[-1] if metrics_tracker.train_losses else None,\n",
        "            \"final_train_acc\": metrics_tracker.train_acc[-1] if metrics_tracker.train_acc else None,\n",
        "            \"final_test_loss\": metrics_tracker.test_losses[-1] if metrics_tracker.test_losses else None,\n",
        "            \"final_test_acc\": metrics_tracker.test_acc[-1] if metrics_tracker.test_acc else None,\n",
        "            \"config\": stage_config\n",
        "        }\n",
        "\n",
        "        metrics_path = f\"{stage_save_dir}/metrics.json\"\n",
        "        with open(metrics_path, 'w') as f:\n",
        "            json.dump(metrics_data, f, indent=2)\n",
        "        print(f\"‚úÖ Saved metrics: {metrics_path}\")\n",
        "\n",
        "        # Save metrics plot (graph with training curves)\n",
        "        plot_path = f\"{stage_save_dir}/training_metrics.png\"\n",
        "        metrics_tracker.plot_metrics(save_path=plot_path)\n",
        "        print(f\"‚úÖ Saved training graphs: {plot_path}\")\n",
        "\n",
        "        all_stage_results[stage_name] = {\n",
        "            \"metrics\": metrics_data,\n",
        "            \"model_path\": final_model_path,\n",
        "            \"plot_path\": plot_path\n",
        "        }\n",
        "\n",
        "        # Set weights path for next stage\n",
        "    if next_stage:\n",
        "        pretrained_weights_path = f\"{Config.SAVE_MODEL_PATH}/weights_for_{next_stage}.pth\"\n",
        "\n",
        "    # Free GPU memory before moving to next stage\n",
        "    if torch.cuda.is_available():\n",
        "        del model  # Delete model to free memory\n",
        "        del metrics_tracker  # Delete metrics tracker\n",
        "        torch.cuda.empty_cache()  # Clear CUDA cache\n",
        "        print(\"üßπ GPU memory cleared for next stage\")\n",
        "\n",
        "    print(f\"\\n‚úÖ Stage {i} completed!\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéâ ALL STAGES COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "if SAVE_RESULTS_AT_EACH_STAGE:\n",
        "    print(\"\\nüìä Results Summary:\")\n",
        "    print(f\"{'Stage':<20} {'Test Accuracy':<15} {'Model Path':<60}\")\n",
        "    print(\"-\"*95)\n",
        "    for stage_name, result in all_stage_results.items():\n",
        "        final_test_acc = result['metrics'].get('final_test_acc', 'N/A')\n",
        "        model_path = result.get('model_path', 'N/A')\n",
        "        if isinstance(final_test_acc, (int, float)):\n",
        "            print(f\"{stage_name:<20} {final_test_acc:<15.2f} {model_path}\")\n",
        "        else:\n",
        "            print(f\"{stage_name:<20} {str(final_test_acc):<15} {model_path}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üìÅ Base Save Directory: {Config.SAVE_MODEL_PATH}\")\n",
        "    if Config.SAVE_MODEL_PATH.startswith('/gdrive'):\n",
        "        print(f\"üìÇ Location: Google Drive (My Drive/models)\")\n",
        "    print(f\"\\nüì¶ For each stage, you'll find:\")\n",
        "    print(f\"  ‚Ä¢ final_model.pth - Trained model weights\")\n",
        "    print(f\"  ‚Ä¢ metrics.json - Training metrics\")\n",
        "    print(f\"  ‚Ä¢ training_metrics.png - Training curves graph\")\n",
        "\n",
        "    # Verify files were actually saved\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"üîç Verifying saved files:\")\n",
        "    verify_saved_files(Config.SAVE_MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt0uYfbpnQlK"
      },
      "outputs": [],
      "source": [
        "\n",
        "drive_model_path = f\"{Config.DRIVE_MODEL_PATH}/final_model.pth\"\n",
        "save_model(model, drive_model_path, epoch=30, loss=0)\n",
        "print(f\"Model also saved to Google Drive: {drive_model_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
