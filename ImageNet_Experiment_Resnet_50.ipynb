{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WacZdFIK8Wxm"
      },
      "source": [
        "# Multi-Dataset ImageNet Training with ResNet50 - Modular Version\n",
        "\n",
        "This notebook demonstrates training ResNet50 on multiple ImageNet variants using a modular approach. The code supports experiments across different datasets for comprehensive analysis.\n",
        "\n",
        "## Supported Datasets:\n",
        "- **ImageNette**: 10 classes, 224x224 images (fastest for experiments)\n",
        "- **Tiny ImageNet**: 200 classes, 64x64 images (medium complexity)\n",
        "- **ImageNet Mini**: 1000 classes, 224x224 images (subset of full ImageNet)\n",
        "- **Full ImageNet**: 1000 classes, 224x224 images (full dataset)\n",
        "\n",
        "## Features:\n",
        "- **Modular Design**: Separate modules for configuration, data loading, models, and training utilities\n",
        "- **Multi-Dataset Support**: Easy switching between different ImageNet variants\n",
        "- **Dataset-Specific Training**: Optimized hyperparameters for each dataset\n",
        "- **Comprehensive Metrics**: Tracks training and validation metrics\n",
        "- **Model Saving**: Automatic model checkpointing with dataset-specific naming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG8Wassd8Wxp",
        "outputId": "5500e1f8-15c0-4e14-f151-3c02b39cd3aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.10)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.2.1)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install torchsummary albumentations\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clone the repo\n",
        "!git clone https://github.com/nitin-vig/ERAv4S9.git\n",
        "\n",
        "# Step 2: Move into the repo folder\n",
        "%cd ERAv4S9\n",
        "\n",
        "# Step 3: (Optional) List files to verify\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9sgaqmb9ghJ",
        "outputId": "ef39468c-2fdd-469c-cc94-79c26ef1b6f0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ERAv4S9'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 35 (delta 12), reused 31 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 166.21 KiB | 20.78 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "/content/ERAv4S9/ERAv4S9/ERAv4S9/ERAv4S9/ERAv4S9/ERAv4S9/ERAv4S9/ERAv4S9/ERAv4S9/ERAv4S9/ERAv4S9\n",
            "total 416\n",
            "-rw-r--r-- 1 root root  20980 Oct 25 22:33 advanced_optimizer_scheduler.py\n",
            "-rw-r--r-- 1 root root  11707 Oct 25 22:33 config.py\n",
            "-rw-r--r-- 1 root root  25532 Oct 25 22:33 dataset_loader.py\n",
            "-rw-r--r-- 1 root root  22334 Oct 25 22:33 enhanced_progressive_training.py\n",
            "-rw-r--r-- 1 root root   7974 Oct 25 22:33 example_usage.py\n",
            "-rw-r--r-- 1 root root 231834 Oct 25 22:33 ImageNet_Experiment_Resnet_50.ipynb\n",
            "-rw-r--r-- 1 root root   6905 Oct 25 22:33 models.py\n",
            "-rw-r--r-- 1 root root  25541 Oct 25 22:33 progressive_training_strategy.py\n",
            "-rw-r--r-- 1 root root  10776 Oct 25 22:33 README.md\n",
            "-rw-r--r-- 1 root root    648 Oct 25 22:33 requirements.txt\n",
            "-rw-r--r-- 1 root root  18632 Oct 25 22:33 strategy_comparison.py\n",
            "-rw-r--r-- 1 root root   5255 Oct 25 22:33 train_imagenet_mini.py\n",
            "-rw-r--r-- 1 root root  11070 Oct 25 22:33 training_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCfedRJU8Wxq",
        "outputId": "26950af5-d34c-46af-f45d-83a1a7196396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful!\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# Import all necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Import our modular components\n",
        "from config import Config\n",
        "from dataset_loader import get_data_loaders, visualize_samples\n",
        "from models import get_model, count_parameters, get_model_summary, save_model\n",
        "from training_utils import train_model, evaluate_model, MetricsTracker\n",
        "\n",
        "print(\"All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LKzKXeB8Wxr"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "Let's configure our training parameters. You can easily switch between datasets and modify training parameters here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sbHsrds8Wxr",
        "outputId": "bd13de9c-6871-477a-bd2d-27e39d34a3c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration updated for imagenette\n",
            "Image size: 224\n",
            "Number of classes: 10\n",
            "Batch size: 64\n",
            "Epochs: 30\n",
            "Learning rate: 0.001\n",
            "Configuration updated!\n",
            "Dataset: imagenette\n",
            "Image size: 224\n",
            "Number of classes: 10\n",
            "Batch size: 64\n",
            "Epochs: 30\n",
            "Learning rate: 0.001\n",
            "Use pretrained: False\n",
            "\n",
            "Dataset-specific parameters:\n",
            "Optimizer: adamw\n",
            "Scheduler: reduce_lr\n"
          ]
        }
      ],
      "source": [
        "# Configuration setup for multi-dataset experiments\n",
        "# You can easily switch between datasets by changing DATASET_NAME\n",
        "\n",
        "# Dataset configuration\n",
        "DATASET_NAME = \"imagenette\"  # Options: \"imagenette\", \"tiny_imagenet\", \"imagenet_mini\", \"imagenet\"\n",
        "USE_PRETRAINED = False  # Custom implementation without pretrained weights\n",
        "\n",
        "# Update configuration for the selected dataset\n",
        "Config.update_for_dataset(DATASET_NAME)\n",
        "\n",
        "print(\"Configuration updated!\")\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"Image size: {Config.IMAGE_SIZE}\")\n",
        "print(f\"Number of classes: {Config.NUM_CLASSES}\")\n",
        "print(f\"Batch size: {Config.BATCH_SIZE}\")\n",
        "print(f\"Epochs: {Config.NUM_EPOCHS}\")\n",
        "print(f\"Learning rate: {Config.LEARNING_RATE}\")\n",
        "print(f\"Use pretrained: {USE_PRETRAINED}\")\n",
        "\n",
        "# Display dataset-specific training parameters\n",
        "dataset_config = Config.get_dataset_config()\n",
        "print(f\"\\nDataset-specific parameters:\")\n",
        "print(f\"Optimizer: {dataset_config['optimizer']}\")\n",
        "print(f\"Scheduler: {dataset_config['scheduler']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTitVrnx8Wxr"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "Setup the environment and check GPU availability. For full ImageNet training, you'll need significant computational resources.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hms3ZX-O8Wxs",
        "outputId": "17ded5ce-3ea3-4cce-fe64-54f698f38993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up environment for ImageNet training...\n",
            "Environment setup complete!\n",
            "Using device: cuda\n",
            "GPU: NVIDIA L4\n",
            "GPU Memory: 23.8 GB\n",
            "Warning: Full ImageNet training requires significant GPU memory!\n"
          ]
        }
      ],
      "source": [
        "# Setup environment\n",
        "def setup_environment():\n",
        "    \"\"\"Setup environment for ImageNet training\"\"\"\n",
        "    print(\"Setting up environment for ImageNet training...\")\n",
        "\n",
        "    # Create necessary directories\n",
        "    os.makedirs(Config.DATA_ROOT, exist_ok=True)\n",
        "    os.makedirs(Config.SAVE_MODEL_PATH, exist_ok=True)\n",
        "\n",
        "    print(\"Environment setup complete!\")\n",
        "\n",
        "def check_gpu_availability():\n",
        "    \"\"\"Check GPU availability and setup device\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        print(\"Warning: Full ImageNet training requires significant GPU memory!\")\n",
        "    else:\n",
        "        print(\"Warning: CPU training will be very slow for ImageNet!\")\n",
        "\n",
        "    return device\n",
        "\n",
        "# Run setup\n",
        "setup_environment()\n",
        "device = check_gpu_availability()\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üß© Colab Dataset Setup Cell\n",
        "# Copy-paste this cell into your Colab notebook\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Install required packages (if not already installed)\n",
        "!pip install -q torch torchvision albumentations tqdm requests\n",
        "\n",
        "DATA_DIR = \"/content/data\"\n",
        "IMAGENETTE_DIR = os.path.join(DATA_DIR, \"imagenette2\")\n",
        "TINY_IMAGENET_DIR = os.path.join(DATA_DIR, \"tiny-imagenet-200\")\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def run_cmd(cmd):\n",
        "    \"\"\"Helper to run shell commands cleanly.\"\"\"\n",
        "    result = subprocess.run(cmd, shell=True, check=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(f\"‚ö†Ô∏è Warning: {cmd} failed with error:\\n{result.stderr}\")\n",
        "    return result\n",
        "\n",
        "# ------------------------------\n",
        "# üîπ Download ImageNette\n",
        "# ------------------------------\n",
        "if not os.path.exists(IMAGENETTE_DIR) or len(os.listdir(IMAGENETTE_DIR)) == 0:\n",
        "    print(\"üîÑ Downloading ImageNette...\")\n",
        "    run_cmd(\"wget -q https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\")\n",
        "    run_cmd(\"tar -xzf imagenette2.tgz\")\n",
        "    run_cmd(f\"mv imagenette2 {DATA_DIR}/\")\n",
        "    run_cmd(\"rm imagenette2.tgz\")\n",
        "    print(\"‚úÖ ImageNette downloaded!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Skipping ImageNette ‚Äî already exists at {IMAGENETTE_DIR}\")\n",
        "\n",
        "# ------------------------------\n",
        "# üîπ Download Tiny ImageNet\n",
        "# ------------------------------\n",
        "if not os.path.exists(TINY_IMAGENET_DIR) or len(os.listdir(TINY_IMAGENET_DIR)) == 0:\n",
        "    print(\"üîÑ Downloading Tiny ImageNet...\")\n",
        "    run_cmd(\"wget -q http://cs231n.stanford.edu/tiny-imagenet-200.zip\")\n",
        "    run_cmd(\"unzip -q tiny-imagenet-200.zip\")\n",
        "    run_cmd(f\"mv tiny-imagenet-200 {DATA_DIR}/\")\n",
        "    run_cmd(\"rm tiny-imagenet-200.zip\")\n",
        "    print(\"‚úÖ Tiny ImageNet downloaded!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Skipping Tiny ImageNet ‚Äî already exists at {TINY_IMAGENET_DIR}\")\n",
        "\n",
        "# ------------------------------\n",
        "# üîπ Verify\n",
        "# ------------------------------\n",
        "print(\"\\nüìÅ Dataset verification:\")\n",
        "!ls -la {DATA_DIR}\n",
        "!du -sh {DATA_DIR}/* | sort -h\n",
        "\n",
        "print(\"\\nüéâ Datasets ready! You can now use:\")\n",
        "print(\"from dataloader import get_data_loaders\")\n",
        "print(\"train_loader, test_loader = get_data_loaders('imagenette')\")\n"
      ],
      "metadata": {
        "id": "WW24PNlCUVQF",
        "outputId": "5b5235bb-b80a-428f-f88d-1b3c11144496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Skipping ImageNette ‚Äî already exists at /content/data/imagenette2\n",
            "‚úÖ Skipping Tiny ImageNet ‚Äî already exists at /content/data/tiny-imagenet-200\n",
            "\n",
            "üìÅ Dataset verification:\n",
            "total 16\n",
            "drwxr-xr-x 4 root root  4096 Oct 25 22:25 .\n",
            "drwxr-xr-x 1 root root  4096 Oct 25 22:21 ..\n",
            "drwxr-xr-x 4  501 staff 4096 Feb  6  2021 imagenette2\n",
            "drwxrwxr-x 5 root root  4096 Feb  9  2015 tiny-imagenet-200\n",
            "481M\t/content/data/tiny-imagenet-200\n",
            "1.5G\t/content/data/imagenette2\n",
            "\n",
            "üéâ Datasets ready! You can now use:\n",
            "from dataloader import get_data_loaders\n",
            "train_loader, test_loader = get_data_loaders('imagenette')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F9rBWIp8Wxs"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "Load the dataset and visualize some sample images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "0HCNpJBv8Wxs",
        "outputId": "b9451ab3-39a5-4e17-b4d2-c29953ba9964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "ImageNette dataset download instructions:\n",
            "1. Download from: https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
            "2. Extract to ./data/imagenette2/\n",
            "3. Ensure folder structure:\n",
            "   imagenette2/\n",
            "   ‚îú‚îÄ‚îÄ train/\n",
            "   ‚îÇ   ‚îú‚îÄ‚îÄ n01440764/\n",
            "   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
            "   ‚îî‚îÄ‚îÄ val/\n",
            "       ‚îú‚îÄ‚îÄ n01440764/\n",
            "       ‚îî‚îÄ‚îÄ ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1750977813.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Visualize some samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ERAv4S9/dataset_loader.py\u001b[0m in \u001b[0;36mget_data_loaders\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;31m# Create data loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdataloader_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdataloader_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "train_loader, test_loader = get_data_loaders(DATASET_NAME)\n",
        "\n",
        "# Visualize some samples\n",
        "print(\"\\nVisualizing sample images...\")\n",
        "visualize_samples(train_loader, num_samples=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KrXECgD8Wxt"
      },
      "source": [
        "## Model Creation\n",
        "\n",
        "Create the ResNet50 model and display its architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ3Qqiq58Wxt"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "print(f\"Creating {Config.MODEL_NAME} model...\")\n",
        "model = get_model(\n",
        "    model_name=Config.MODEL_NAME,\n",
        "    dataset_name=DATASET_NAME,\n",
        "    pretrained=USE_PRETRAINED\n",
        ")\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Print model info\n",
        "print(f\"Model parameters: {count_parameters(model):,}\")\n",
        "\n",
        "# Get model summary\n",
        "dataset_config = Config.get_dataset_config()\n",
        "input_size = (3, dataset_config[\"image_size\"], dataset_config[\"image_size\"])\n",
        "print(f\"\\nModel summary (input size: {input_size}):\")\n",
        "get_model_summary(model, input_size=input_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEBryc3p8Wxt"
      },
      "source": [
        "## Training\n",
        "\n",
        "Train the model using our modular training utilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1XNO6oM8Wxt"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "stage_config = Config.STAGES[DATASET_NAME]\n",
        "NUM_EPOCHS = stage_config[\"epochs\"]\n",
        "BATCH_SIZE = stage_config[\"batch_size\"]\n",
        "LEARNING_RATE = stage_config[\"lr\"]\n",
        "WEIGHT_DECAY = stage_config[\"weight_decay\"]\n",
        "\n",
        "print(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
        "\n",
        "metrics_tracker = train_model(model, train_loader, test_loader, device, Config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM55R49L8Wxu"
      },
      "source": [
        "## Results Visualization\n",
        "\n",
        "Plot the training metrics and evaluate the final model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T6kFw9s8Wxu"
      },
      "outputs": [],
      "source": [
        "# Plot training metrics\n",
        "print(\"Plotting training metrics...\")\n",
        "metrics_tracker.plot_metrics(save_path=f\"{Config.SAVE_MODEL_PATH}/training_metrics.png\")\n",
        "\n",
        "# Final evaluation\n",
        "print(\"\\nFinal evaluation...\")\n",
        "test_loss, test_acc, test_top5_acc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "print(f\"\\nTraining completed!\")\n",
        "print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
        "print(f\"Final Top-5 Accuracy: {test_top5_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-rY31PS8Wxu"
      },
      "source": [
        "## Model Saving\n",
        "\n",
        "Save the trained model to local storage and Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6ch59xH8Wxu"
      },
      "outputs": [],
      "source": [
        "# Save final model\n",
        "final_model_path = f\"{Config.SAVE_MODEL_PATH}/final_model.pth\"\n",
        "save_model(model, final_model_path, epoch=NUM_EPOCHS, loss=test_loss)\n",
        "\n",
        "# Save to Google Drive if mounted\n",
        "if Config.MOUNT_DRIVE:\n",
        "    drive_model_path = f\"{Config.DRIVE_MODEL_PATH}/final_model.pth\"\n",
        "    save_model(model, drive_model_path, epoch=NUM_EPOCHS, loss=test_loss)\n",
        "    print(f\"Model also saved to Google Drive: {drive_model_path}\")\n",
        "\n",
        "print(\"Model saving completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axK0xjbV8Wxv"
      },
      "source": [
        "## Multi-Dataset Experiments\n",
        "\n",
        "You can easily switch between different datasets for experiments. Each dataset has optimized hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "WCEBGAI38Wxv",
        "outputId": "4a2657d2-176f-458a-d7e4-8efd6c3d93db"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'config' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-828907700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Uncomment the dataset you want to experiment with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Example 1: ImageNette (fastest, 10 classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDATASET_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"imagenette\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
          ]
        }
      ],
      "source": [
        "# Multi-dataset experiment examples\n",
        "# Uncomment the dataset you want to experiment with\n",
        "\n",
        "# Example 1: ImageNette (fastest, 10 classes)\n",
        "DATASET_NAME = \"imagenette\"\n",
        "Config.update_for_dataset(DATASET_NAME)\n",
        "\n",
        "# Example 2: Tiny ImageNet (medium complexity, 200 classes)\n",
        "# DATASET_NAME = \"tiny_imagenet\"\n",
        "# Config.update_for_dataset(DATASET_NAME)\n",
        "\n",
        "# Example 3: ImageNet Mini (1000 classes subset)\n",
        "# DATASET_NAME = \"imagenet_mini\"\n",
        "# Config.update_for_dataset(DATASET_NAME)\n",
        "\n",
        "# Example 4: Full ImageNet (1000 classes, full dataset)\n",
        "# DATASET_NAME = \"imagenet\"\n",
        "# Config.update_for_dataset(DATASET_NAME)\n",
        "\n",
        "print(\"To experiment with different datasets:\")\n",
        "print(\"1. Uncomment the dataset you want to use\")\n",
        "print(\"2. Run this cell to update configuration\")\n",
        "print(\"3. Continue with the rest of the notebook\")\n",
        "print(\"\\nDataset comparison:\")\n",
        "print(\"- ImageNette: ~13k images, 10 classes, ~30 epochs\")\n",
        "print(\"- Tiny ImageNet: ~100k images, 200 classes, ~50 epochs\")\n",
        "print(\"- ImageNet Mini: ~100k images, 1000 classes, ~50 epochs\")\n",
        "print(\"- Full ImageNet: ~1.2M images, 1000 classes, ~90 epochs\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOSlh9n4c-hH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-GYmfW8dGpQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8UX7LDdHa0"
      },
      "source": [
        "\n",
        "\n",
        "# Tiny ImageNet with Resnet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XzvJLus2WJ2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP6zxmOEaOvv"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torch import nn, optim\n",
        "# from torch_lr_finder import LRFinder\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # 3. Instantiate model, optimizer, and criterion\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# # Assuming 'model' is already defined and on the correct device\n",
        "# # e.g., model = resnet34_cifar().to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-7)  # Start with a very small LR\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# # 4. Run the LR finder\n",
        "# lr_finder = LRFinder(model, optimizer, criterion, device=device)\n",
        "# lr_finder.range_test(train_loader, end_lr=0.1, num_iter=300)\n",
        "# # 5. Plot the results\n",
        "# lr_finder.plot()\n",
        "\n",
        "# # 6. Reset the model and optimizer to their initial states\n",
        "# lr_finder.reset()\n",
        "# #>>>>>>>>4.32e-03 for batch size 128,\n",
        "# # LR: 9.05E-03 for batch size 256\n",
        "# ##Suggested LR: 7.88E-03 for  batch size 512\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBIyJ5Y05qWz"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}